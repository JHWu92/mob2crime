{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/Jiahui/mob2crime'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if not os.getcwd().endswith('mob2crime'):\n",
    "    os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, json, glob\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from src.creds import mex_root, mex_tower_fn\n",
    "\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(call_in_or_out='out+in', debugging=True)\n"
     ]
    }
   ],
   "source": [
    "args_list = '--call-in-or-out out+in --debugging'.split()\n",
    "parser = argparse.ArgumentParser(description='options for aggregating mexico tower daily hourly unique user in call-out or call-in data')\n",
    "parser.add_argument('--debugging', action='store_true')\n",
    "parser.add_argument('--call-in-or-out', required=True, choices=['in','out', 'out+in'])\n",
    "args = parser.parse_args(args_list)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = logging.DEBUG if args.debugging else logging.INFO\n",
    "logging.basicConfig(filename=\"logs/StatMexTwHrUniqCnt.log\", level=level, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats/MexTwHrUniqCnt-out/debug/\n"
     ]
    }
   ],
   "source": [
    "stat_dir = f'stats/MexTwHrUniqCnt-{args.call_in_or_out}/'\n",
    "if args.debugging:\n",
    "    stat_dir += 'debug/'\n",
    "print('statistics in ', stat_dir)\n",
    "os.makedirs(stat_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('===============================')\n",
    "logging.info('MEX tower hourly unique user counting starts. '\n",
    "             f'debugging={args.debugging}, call_in_or_out={args.call_in_or_out}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tower ids information\n",
    "tower_info_path = mex_root+ mex_tower_fn\n",
    "towers = pd.read_csv(tower_info_path,header=None,sep='|')\n",
    "towers['latlon'] = towers.apply(lambda x: '%.6f'%(x[2])+','+'%.6f'%(x[3]), axis=1)\n",
    "towers_gp = towers.groupby('latlon')[0].apply(list).to_frame()\n",
    "towers_gp['gtid'] = towers_gp[0].apply(lambda x: '-'.join(x))\n",
    "\n",
    "gt2loc = {row['gtid']: loc.split(',') for loc, row in towers_gp.iterrows()}\n",
    "t2gt = {}\n",
    "for _, row in towers_gp.iterrows():\n",
    "    for tid in row[0]:\n",
    "        t2gt[tid] = row['gtid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQueue:\n",
    "    def __init__(self,directory, maxlen=6):\n",
    "        self.directory = directory\n",
    "        self.maxlen = maxlen\n",
    "        self.dates = deque(maxlen=6)\n",
    "        self.aggs = {}\n",
    "    def get_agg(self, date):\n",
    "        if date not in self.aggs:\n",
    "            loaded = self.load_agg(date)\n",
    "            if not loaded:\n",
    "#                 print(f'get_agg {date} can not be loaded')\n",
    "                return None\n",
    "        return self.aggs[date]\n",
    "    \n",
    "    def load_agg(self, date):\n",
    "        if set(self.dates) != set(self.aggs.keys()):\n",
    "            self.dates = [d for d in self.dates if d in self.aggs]\n",
    "        fn = f'{self.directory}{date}.json.gz'\n",
    "        if not os.path.exists(fn):\n",
    "            return False\n",
    "        if len(self.dates)==self.maxlen:\n",
    "            self.aggs.pop(self.dates.popleft())\n",
    "        self.dates.append(date)\n",
    "        agg = json.load(gzip.open(fn))\n",
    "#         agg=fn\n",
    "        self.aggs[date] = agg\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_stat_by_agg(stat, stat_no_tinfo, agg):\n",
    "    for tid, hr_uniq_users in agg.items():\n",
    "        tid = tid.replace('33F430','')\n",
    "        if tid in t2gt:\n",
    "            gtid = t2gt[tid]\n",
    "            for hr, uniq_users in hr_uniq_users.items():\n",
    "                stat[gtid][int(hr)].update(uniq_users)\n",
    "        else: \n",
    "            for hr, uniq_users in hr_uniq_users.items():\n",
    "                stat_no_tinfo[tid][int(hr)].update(uniq_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out', 'in']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_directions = args.call_in_or_out.split('+')\n",
    "call_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating task list\n",
    "agg_dir = {'in': 'stats/AggMexTwDyHrUnqUsrVOZENTRANTE/', 'out': 'stats/AggMexTwDyHrUnqUsrVOZ/'}\n",
    "dates_in_file = {}\n",
    "data_queues = {}\n",
    "dates = set()\n",
    "for call_d in call_directions:\n",
    "    adir = agg_dir[call_d]\n",
    "    dates_in_file[call_d] = json.load(open(f'{adir}dates_in_file.json'))\n",
    "    dates.update(dates_in_file[call_d].keys())\n",
    "    data_queues[call_d] = DataQueue(directory=adir, maxlen=6)\n",
    "\n",
    "dates = sorted(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on date: 2009-10-01\n",
      "out ['2009-10-01']\n",
      "2009-10-01 not in call_direction: in\n"
     ]
    }
   ],
   "source": [
    "# for each date\n",
    "for date in dates:\n",
    "    print(f'working on date: {date}')\n",
    "    logging.info(f'working on date: {date}')\n",
    "    \n",
    "    # compiling stat: stats[tower][hour] = set of users\n",
    "    stat = defaultdict(lambda: defaultdict(set))\n",
    "    stat_no_tinfo = defaultdict(lambda: defaultdict(set))\n",
    "    \n",
    "    # get agg_file_dates in each call direction of interests for each date \n",
    "    for call_d in call_directions:\n",
    "        if date not in dates_in_file[call_d]:\n",
    "            print(f'{date} not in call_direction: {call_d}')\n",
    "            logging.info(f'{date} not in call_direction: {call_d}')\n",
    "            continue\n",
    "        agg_dates = dates_in_file[call_d][date]\n",
    "        if args.debugging: print(call_d, agg_dates)\n",
    "        # update the unique users set of each hour in that date by each agg_file in each call direction \n",
    "        for adate in agg_dates:\n",
    "            agg = data_queues[call_d].get_agg(adate)[date]\n",
    "            update_stat_by_agg(stat, stat_no_tinfo, agg)\n",
    "#             break\n",
    "    # store stat\n",
    "    df_stat = pd.DataFrame(stat).T.applymap(lambda x: len(x) if not pd.isnull(x) else 0)\n",
    "    df_stat.to_csv(f\"{stat_dir}{date}-located.csv\")\n",
    "    df_stat_no_tinfo = pd.DataFrame(stat_no_tinfo).T.applymap(lambda x: len(x) if not pd.isnull(x) else 0)\n",
    "    df_stat_no_tinfo.to_csv(f\"{stat_dir}{date}-no-info.csv\")\n",
    "    logging.info('%d towers located, %d towers no info' %(len(df_stat), len(df_stat_no_tinfo)))\n",
    "    if args.debugging:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('finish counting')\n",
    "logging.info('*'*20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
